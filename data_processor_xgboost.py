"""
Data Processor XGBoost - RÃ©plica COMPLETA del Pipeline__2_
Genera exactamente las 157 features que el modelo espera
"""

import pandas as pd
import numpy as np
import os
import joblib
from typing import Dict, Tuple

class DataProcessorXGBoost:
    """
    Procesador que replica EXACTAMENTE el Pipeline__2_.ipynb
    Incluye todas las transformaciones y mÃ©tricas de calificaciones
    """
    
    def __init__(self, model_dir='.'):
        """Inicializa el procesador y carga el modelo"""
        self.model_dir = model_dir
        self.modelo = None
        self.scaler = None
        self.columnas_modelo = None
        
        # Cargar archivo de categorÃ­as
        self.categorias = None
        self._cargar_categorias()
        
        # Cargar modelo
        self._cargar_modelo()
    
    def _cargar_categorias(self):
        """Carga el archivo de categorÃ­as para mapear materias"""
        try:
            categorias_path = 'Ejemplo__1_.xlsx'
            
            if os.path.exists(categorias_path):
                self.categorias = pd.read_excel(categorias_path, sheet_name='Hoja1')
                # Crear diccionario de mapeo
                self.mapa_categorias = dict(zip(
                    self.categorias['Clase'], 
                    self.categorias['CategorÃ­a ']
                ))
                print(f"âœ… CategorÃ­as cargadas: {len(self.mapa_categorias)} materias mapeadas")
            else:
                print("âš ï¸ Archivo de categorÃ­as no encontrado, usando mapeo por defecto")
                self.mapa_categorias = {}
                
        except Exception as e:
            print(f"âš ï¸ Error cargando categorÃ­as: {e}")
            self.mapa_categorias = {}
    
    def _cargar_modelo(self):
        """Carga el modelo XGBoost y archivos auxiliares"""
        try:
            modelo_path = 'xgboost_modelo.pkl'
            scaler_path = 'scaler.pkl'
            columnas_path = 'columnas.pkl'
            
            print("ðŸ” DEBUG: Iniciando carga del modelo...")
            print(f"   Ruta esperada: {modelo_path}")
            print(f"   Directorio actual: {os.getcwd()}")
            
            # Intentar descargar si no existe
            if not os.path.exists(modelo_path):
                print("ðŸ” Modelo no encontrado localmente, intentando descargar...")
                self._descargar_modelo()
            
            # Verificar que existe despuÃ©s de descargar
            if not os.path.exists(modelo_path):
                raise FileNotFoundError(
                    f"âŒ Modelo no encontrado: {modelo_path}\n"
                    f"   Verifica que el archivo se descargÃ³ correctamente de Google Drive"
                )
            
            print(f"âœ“ Archivo encontrado: {modelo_path}")
            print(f"  TamaÃ±o: {os.path.getsize(modelo_path) / 1024 / 1024:.2f} MB")
            
            # Cargar modelo
            print("  Cargando modelo con joblib...")
            self.modelo = joblib.load(modelo_path)
            print("âœ… Modelo XGBoost cargado exitosamente")
            
            # Cargar scaler (opcional)
            if os.path.exists(scaler_path):
                self.scaler = joblib.load(scaler_path)
                print("âœ… Scaler cargado")
            else:
                self.scaler = None
                print("âš ï¸  scaler.pkl no encontrado - continuando sin estandarizaciÃ³n previa")
            
            # Cargar columnas (opcional)
            if os.path.exists(columnas_path):
                self.columnas_modelo = joblib.load(columnas_path)
                print("âœ… Columnas del modelo cargadas")
            else:
                self.columnas_modelo = None
                print("âš ï¸  columnas.pkl no encontrado - usando todas las columnas disponibles")
            
        except Exception as e:
            print(f"âŒ Error cargando modelo: {str(e)}")
            import traceback
            traceback.print_exc()
            self.modelo = None
            self.scaler = None
            self.columnas_modelo = None
    
    def _descargar_modelo(self):
        """Descarga el modelo desde Google Drive"""
        modelo_path = 'xgboost_modelo.pkl'
        
        if not os.path.exists(modelo_path):
            print("â¬‡ï¸ Descargando modelo desde Google Drive...")
            print("   TamaÃ±o: ~142 MB - Esto puede tomar 1-2 minutos")
            
            try:
                import gdown
                
                file_id = "1VLySTpc2m4soxTEjTi7xUSJcXyrF00JF"
                
                try:
                    url = f"https://drive.google.com/uc?id={file_id}"
                    gdown.download(url, modelo_path, quiet=False, fuzzy=True)
                    print("âœ… Modelo descargado exitosamente")
                    return
                except Exception as e1:
                    print(f"âš ï¸ MÃ©todo 1 fallÃ³: {str(e1)}")
                    
                    try:
                        gdown.cached_download(url, modelo_path, quiet=False)
                        print("âœ… Modelo descargado exitosamente (mÃ©todo 2)")
                        return
                    except Exception as e2:
                        print(f"âš ï¸ MÃ©todo 2 fallÃ³: {str(e2)}")
                        print("   Intentando mÃ©todo 3 (requests)...")
                        import requests
                        
                        download_url = f"https://drive.google.com/uc?export=download&id={file_id}"
                        session = requests.Session()
                        response = session.get(download_url, stream=True)
                        
                        for key, value in response.cookies.items():
                            if key.startswith('download_warning'):
                                download_url = f"https://drive.google.com/uc?export=download&confirm={value}&id={file_id}"
                                response = session.get(download_url, stream=True)
                                break
                        
                        with open(modelo_path, 'wb') as f:
                            for chunk in response.iter_content(chunk_size=32768):
                                if chunk:
                                    f.write(chunk)
                        
                        print("âœ… Modelo descargado exitosamente (mÃ©todo 3)")
                        
            except Exception as e:
                print(f"âŒ Error descargando: {str(e)}")
                print("   SoluciÃ³n: Sube el archivo 'xgboost_modelo.pkl' manualmente")
        else:
            print("âœ… Modelo ya existe localmente")
    
    def procesar_archivo_excel(self, archivo_path):
        """Procesa un archivo Excel con 4 hojas"""
        notas = pd.read_excel(archivo_path, sheet_name='NOTAS')
        per = pd.read_excel(archivo_path, sheet_name='PER')
        prom = pd.read_excel(archivo_path, sheet_name='PROM')
        adm = pd.read_excel(archivo_path, sheet_name='ADM')
        return self._pipeline_completo(notas, per, prom, adm)
    
    def procesar_dataframes(self, notas_df, per_df, prom_df, adm_df) -> pd.DataFrame:
        """Procesa 4 DataFrames separados (para Streamlit)"""
        return self._pipeline_completo(notas_df, per_df, prom_df, adm_df)
    
    def _pipeline_completo(self, notas, per, prom, adm) -> pd.DataFrame:
        """Implementa el Pipeline__2_.ipynb COMPLETO"""
        print("\n" + "="*70)
        print("ðŸ”„ INICIANDO PIPELINE DE PROCESAMIENTO COMPLETO")
        print("="*70)
        
        # FASE 1: Limpiezas y renames
        print("\nðŸ“Š FASE 1: Limpieza de bases individuales")
        notas = self._procesar_notas(notas)
        per, per_original = self._procesar_per(per)
        prom = self._procesar_prom(prom)
        adm = self._procesar_adm(adm)
        
        # FASE 2: Filtros generales
        print("\nðŸ” FASE 2: Aplicando filtros")
        per, prom = self._aplicar_filtros_generales(per, prom, per_original)
        
        # FASE 3: IDs comunes
        print("\nðŸ”— FASE 3: Filtrando IDs comunes")
        notas, per, prom, adm = self._filtrar_ids_comunes(notas, per, prom, adm)
        
        # FASE 4: FusiÃ³n secuencial
        print("\nðŸ”€ FASE 4: Fusionando bases")
        data_fusionada = self._fusionar_bases(per, prom, notas, adm)
        
        # FASE 5: Calcular mÃ©tricas de calificaciones
        print("\nðŸ“Š FASE 5: Calculando mÃ©tricas de calificaciones")
        data_con_metricas = self._calcular_metricas_calificaciones(data_fusionada, notas)
        
        # FASE 6: Limpieza final y encoding
        print("\nðŸ§¹ FASE 6: Limpieza final y encoding")
        data_final = self._limpieza_y_encoding_final(data_con_metricas)
        
        print("\n" + "="*70)
        print(f"âœ… PIPELINE COMPLETADO: {len(data_final)} registros, {len(data_final.columns)} columnas")
        print("="*70)
        
        return data_final
    
    def _procesar_notas(self, notas):
        """Procesa la base NOTAS"""
        print("  ðŸ“‹ Procesando NOTAS...")
        
        # RENOMBRAR COLUMNAS
        rename_dict = {
            'Grado AcadÃ©mico': 'Mult Programa',
            'Programa AcadÃ©mico Base': 'Programa',
            'Promedio_Ciclo': 'Promedio Ciclo',
            'Estado.1': 'Estado Clase'
        }
        notas.rename(columns=rename_dict, inplace=True)
        
        # Eliminar columnas innecesarias
        cols_drop = ['Nombre', 'NÂº Oferta', 'NÂº Clase', 'SesiÃ³n', 'SecciÃ³n', 'Motivo']
        notas.drop(columns=[c for c in cols_drop if c in notas.columns], inplace=True)
        
        print(f"    âœ“ NOTAS procesadas: {len(notas)} registros")
        return notas
    
    def _procesar_per(self, per):
        """Procesa la base PER"""
        print("  ðŸ‘¤ Procesando PER...")
        
        # RENOMBRAR COLUMNAS
        rename_dict = {
            'Grado AcadÃ©mico': 'Mult Programa',
            'Matrd Progr': 'CrÃ©ditos Inscritos en Ciclo',
            'Cred. Aprob.': 'CrÃ©d.Inscritos y Aprobados Ciclo',
            'Ccl Admis': 'Ciclo AdmisiÃ³n',
            'Lugar Nacimiento': 'Ciudad Nacimiento',
            'Acc Prog': 'AcciÃ³n',
            'Motivo AcciÃ³n': 'Motivo'
        }
        per.rename(columns=rename_dict, inplace=True)
        
        per_original = per.copy()
        print(f"    âœ“ PER procesada: {len(per)} registros")
        return per, per_original
    
    def _procesar_prom(self, prom):
        """Procesa la base PROM"""
        print("  ðŸ“ˆ Procesando PROM...")
        
        # RENOMBRAR COLUMNAS
        rename_dict = {
            'Grado': 'Mult Programa',
            'Situacion Academica': 'Situacion Acad',
            'CrÃ©d.Inscrtos y Aprobdos Ciclo': 'CrÃ©d.Inscritos y Aprobados Ciclo',
            'Estado Programa AcadÃ©mico': 'Estado',
            'AcciÃ³n Programa': 'AcciÃ³n',
            'Motivo Accion': 'Motivo'
        }
        prom.rename(columns=rename_dict, inplace=True)
        
        print(f"    âœ“ PROM procesada: {len(prom)} registros")
        return prom
    
    def _procesar_adm(self, adm):
        """Procesa la base ADM"""
        print("  ðŸŽ“ Procesando ADM...")
        
        # RENOMBRAR COLUMNAS
        rename_dict = {
            'Ciclo': 'Ciclo AdmisiÃ³n',
            'PaÃ­s': 'PaÃ­s Nacimiento',
            'Estado': 'Dpto Nacimiento',
            'Programa AcadÃ©mico': 'Programa',
            'Ciudad': 'Ciudad (DirecciÃ³n)',
            'ID Org Ext': 'ID Colegio',
            'Descr': 'Colegio',
            'Estado.1': 'Estado'
        }
        adm.rename(columns=rename_dict, inplace=True)
        
        # Filtrar solo estudiantes activos
        if 'Estado' in adm.columns:
            adm = adm[adm["Estado"] == "Activo en Programa"].copy()
            print(f"    â†’ Filtrados estudiantes activos")
        
        print(f"    âœ“ ADM procesada: {len(adm)} registros")
        return adm
    
    def _aplicar_filtros_generales(self, per, prom, per_original):
        """Aplica los filtros generales del pipeline"""
        # Eliminar ciclo mÃ¡ximo
        ciclo_max_per = per['Ciclo'].max()
        ciclo_max_prom = prom['Ciclo'].max()
        
        per = per[per['Ciclo'] != ciclo_max_per].copy()
        prom = prom[prom['Ciclo'] != ciclo_max_prom].copy()
        
        print(f"    â†’ Ciclo mÃ¡ximo PER eliminado: {ciclo_max_per}")
        print(f"    â†’ Ciclo mÃ¡ximo PROM eliminado: {ciclo_max_prom}")
        
        # Eliminar UCollege
        per = per[per['Programa'] != 'UCollege Javeriano'].copy()
        prom = prom[prom['Programa'] != 'UCollege Javeriano'].copy()
        print(f"    â†’ UCollege eliminado")
        
        # Filtrar solo ciclos que terminan en 10 o 30
        per = per[per['Ciclo'].astype(str).str.endswith(('10', '30'))].copy()
        prom = prom[prom['Ciclo'].astype(str).str.endswith(('10', '30'))].copy()
        print(f"    â†’ Ciclos filtrados (solo 10 y 30)")
        
        # Eliminar registros con 0 crÃ©ditos
        if 'CrÃ©ditos Inscritos en Ciclo' in per.columns:
            per = per[per['CrÃ©ditos Inscritos en Ciclo'] > 0].copy()
            print(f"    â†’ Registros con 0 crÃ©ditos eliminados")
        
        return per, prom
    
    def _filtrar_ids_comunes(self, notas, per, prom, adm):
        """Filtra solo IDs que estÃ©n en las 4 bases"""
        ids_comunes = set(notas["ID"]) & set(per["ID"]) & set(prom["ID"]) & set(adm["ID"])
        
        notas = notas[notas["ID"].isin(ids_comunes)].copy()
        per = per[per["ID"].isin(ids_comunes)].copy()
        prom = prom[prom["ID"].isin(ids_comunes)].copy()
        adm = adm[adm["ID"].isin(ids_comunes)].copy()
        
        print(f"    â†’ IDs comunes: {len(ids_comunes)}")
        
        return notas, per, prom, adm
    
    def _fusionar_bases(self, per, prom, notas, adm):
        """Fusiona las 4 bases secuencialmente"""
        # 1. PER + PROM
        per_prom = per.merge(
            prom,
            on=['ID', 'Mult Programa', 'Programa', 'Ciclo'],
            how='inner',
            suffixes=('_per', '_prom')
        )
        print(f"    1. PER + PROM = {len(per_prom)} registros")
        
        # 2. (PER+PROM) + NOTAS
        per_prom_notas = per_prom.merge(
            notas,
            on=['ID', 'Mult Programa', 'Programa', 'Ciclo'],
            how='left',
            suffixes=('_pprom', '_notas')
        )
        print(f"    2. (PER+PROM) + NOTAS = {len(per_prom_notas)} registros")
        
        # 3. (PER+PROM+NOTAS) + ADM
        data_final = per_prom_notas.merge(
            adm,
            on=['ID', 'Programa'],
            how='left',
            suffixes=('_ppn', '_adm')
        )
        print(f"    3. (PER+PROM+NOTAS) + ADM = {len(data_final)} registros")
        
        return data_final
    
    def _calcular_metricas_calificaciones(self, data, notas):
        """
        Calcula mÃ©tricas de calificaciones por estudiante/ciclo
        RÃ©plica de calcular_metricas_calificaciones_paso2_optimizado
        """
        print("    ðŸ”¢ Calculando mÃ©tricas...")
        
        # Agrupar por ID, Mult Programa, Ciclo
        grupos = notas.groupby(['ID', 'Mult Programa', 'Ciclo'])
        
        metricas_lista = []
        
        for (id_est, mult_prog, ciclo), grupo in grupos:
            if 'Calif' not in grupo.columns or 'Uni Matrd' not in grupo.columns:
                continue
            
            califs = grupo['Calif'].values
            creditos = grupo['Uni Matrd'].values
            
            if len(califs) == 0:
                continue
            
            # Calcular mÃ©tricas
            promedio = np.average(califs, weights=creditos)
            
            if len(califs) > 1:
                varianza = np.average((califs - promedio)**2, weights=creditos)
                desviacion = np.sqrt(varianza)
            else:
                desviacion = 0.0
            
            # MIN y sus detalles
            idx_min = grupo['Calif'].idxmin()
            min_calif = grupo.loc[idx_min, 'Calif']
            min_creditos = grupo.loc[idx_min, 'Uni Matrd']
            min_id_curso = grupo.loc[idx_min, 'ID Curso'] if 'ID Curso' in grupo.columns else ''
            min_descripcion = grupo.loc[idx_min, 'DescripciÃ³n'] if 'DescripciÃ³n' in grupo.columns else 'Sin datos'
            
            # MAX y sus detalles
            idx_max = grupo['Calif'].idxmax()
            max_calif = grupo.loc[idx_max, 'Calif']
            max_creditos = grupo.loc[idx_max, 'Uni Matrd']
            max_id_curso = grupo.loc[idx_max, 'ID Curso'] if 'ID Curso' in grupo.columns else ''
            max_descripcion = grupo.loc[idx_max, 'DescripciÃ³n'] if 'DescripciÃ³n' in grupo.columns else 'Sin datos'
            
            # Rango ponderado
            contribuciones = califs * creditos
            rango_ponderado = contribuciones.max() - contribuciones.min()
            
            metricas_lista.append({
                'ID': id_est,
                'Mult Programa': mult_prog,
                'Ciclo': ciclo,
                'Promedio_Ciclo': round(promedio, 2),
                'Des_Estandar_Ciclo': round(desviacion, 2),
                'Min_Ciclo': round(min_calif, 2),
                'Cred_Min_Calif_Ciclo': min_creditos,
                'ID_Min_Ciclo': min_id_curso,
                'Clase_Min_Ciclo': str(min_descripcion),
                'Max_Ciclo': round(max_calif, 2),
                'Cred_Max_Calif_Ciclo': max_creditos,
                'ID_Max_Ciclo': max_id_curso,
                'Clase_Max_Ciclo': str(max_descripcion),
                'Rango_Ponderado_Ciclo': round(rango_ponderado, 2)
            })
        
        metricas_df = pd.DataFrame(metricas_lista)
        
        # Merge con data
        data_con_metricas = data.merge(
            metricas_df,
            on=['ID', 'Mult Programa', 'Ciclo'],
            how='left'
        )
        
        # Rellenar NaN
        data_con_metricas['Clase_Min_Ciclo'].fillna('Sin datos', inplace=True)
        data_con_metricas['Clase_Max_Ciclo'].fillna('Sin datos', inplace=True)
        
        print(f"    âœ“ MÃ©tricas calculadas: {len(metricas_df)} grupos")
        
        return data_con_metricas
    
    def _limpieza_y_encoding_final(self, data):
        """Limpieza final y generaciÃ³n de todas las variables dummy"""
        print("    ðŸ§¹ Iniciando limpieza y encoding...")
        print(f"       Columnas antes: {len(data.columns)}")
        
        # ============================================================
        # PASO CRÃTICO: CALCULAR SIGLAS PROG (del Pipeline__2_)
        # ============================================================
        # Calcular la moda de Prog Acad_ppn por grupo (Mult Programa + Programa)
        if 'Prog Acad_ppn' in data.columns and 'Mult Programa' in data.columns and 'Programa' in data.columns:
            print("       â†’ Calculando 'Siglas Prog' desde Prog Acad_ppn (moda por grupo)...")
            
            moda_por_grupo = (
                data.groupby(["Mult Programa", "Programa"])["Prog Acad_ppn"]
                .agg(lambda x: x.mode().iloc[0] if not x.mode().empty else None)
                .reset_index()
                .rename(columns={"Prog Acad_ppn": "Prog Acad_ppn_moda"})
            )
            
            # Unir la moda con el dataframe
            data = data.merge(moda_por_grupo, on=["Mult Programa", "Programa"], how="left")
            
            # Crear Siglas Prog normalizado
            data["Siglas Prog"] = data["Prog Acad_ppn_moda"]
            
            # Limpiar columnas auxiliares
            data.drop(columns=["Prog Acad_ppn_moda"], inplace=True, errors='ignore')
            
            print(f"         âœ“ Siglas Prog calculadas: {data['Siglas Prog'].nunique()} valores Ãºnicos")
        
        elif 'Prog Acad' in data.columns:
            print("       â†’ Usando 'Prog Acad' como 'Siglas Prog' (fallback)...")
            data['Siglas Prog'] = data['Prog Acad']
        else:
            print("       âš ï¸ NO se puede crear 'Siglas Prog' - NO HAY Prog Acad")
        
        # Normalizar Clase_Min_Ciclo y Clase_Max_Ciclo
        if 'Clase_Min_Ciclo' in data.columns:
            data['Clase_Min_Ciclo'] = data['Clase_Min_Ciclo'].str.title()
            print(f"       âœ“ Clase_Min_Ciclo normalizada: {data['Clase_Min_Ciclo'].nunique()} valores Ãºnicos")
        if 'Clase_Max_Ciclo' in data.columns:
            data['Clase_Max_Ciclo'] = data['Clase_Max_Ciclo'].str.title()
            print(f"       âœ“ Clase_Max_Ciclo normalizada: {data['Clase_Max_Ciclo'].nunique()} valores Ãºnicos")
        
        # Mapear a categorÃ­as
        if self.mapa_categorias and len(self.mapa_categorias) > 0:
            if 'Clase_Min_Ciclo' in data.columns:
                print("       â†’ Mapeando Clase_Min_Ciclo a categorÃ­as...")
                data['Cat_ClaseMin'] = data['Clase_Min_Ciclo'].map(self.mapa_categorias)
                data['Cat_ClaseMin'] = data['Cat_ClaseMin'].fillna('Otros')
                print(f"         CategorÃ­as Min Ãºnicas: {data['Cat_ClaseMin'].nunique()}")
            
            if 'Clase_Max_Ciclo' in data.columns:
                print("       â†’ Mapeando Clase_Max_Ciclo a categorÃ­as...")
                data['Cat_ClaseMax'] = data['Clase_Max_Ciclo'].map(self.mapa_categorias)
                data['Cat_ClaseMax'] = data['Cat_ClaseMax'].fillna('Otros')
                print(f"         CategorÃ­as Max Ãºnicas: {data['Cat_ClaseMax'].nunique()}")
        
        # ============================================================
        # LIMPIAR CIUDAD (DIRECCIÃ“N) - Convertir valores invÃ¡lidos a 'Otro'
        # ============================================================
        def limpiar_ciudad(col_ciudad):
            """Convierte valores no vÃ¡lidos a 'Otro'"""
            import re
            
            valores_a_otro = [
                'Rm', 'Ma', 'Ar', 'La', 'Lp', 'Zu', 'Bo', 'An', 'Po', 'Pr', 'Ct',
                'Co', 'Sp', 'Ta', 'Lo', 'Sc', 'Nsw', 'Gt Lon', 'Ccs', 'Qroo',
                '92500 Rueil-Malmaison', 'Roma Rm', 'Otro'
            ]
            
            def debe_ser_otro(valor):
                if pd.isna(valor):
                    return False
                
                valor_str = str(valor).strip()
                
                if valor_str in valores_a_otro:
                    return True
                
                valor_sin_espacios = valor_str.replace(' ', '')
                if len(valor_sin_espacios) <= 2:
                    return True
                
                if re.match(r'^[A-Z]{2,3}$', valor_sin_espacios):
                    return True
                
                if re.match(r'^\d+', valor_str):
                    return True
                
                return False
            
            return col_ciudad.apply(lambda x: 'Otro' if debe_ser_otro(x) else x)
        
        # Buscar y limpiar Ciudad (DirecciÃ³n)
        col_ciudad = None
        for c in data.columns:
            if 'Ciudad' in c and 'DirecciÃ³n' in c:
                col_ciudad = c
                break
        
        if col_ciudad:
            print(f"       â†’ Limpiando ciudades invÃ¡lidas en {col_ciudad}...")
            data[col_ciudad] = limpiar_ciudad(data[col_ciudad])
        
        # ============================================================
        # ENCODING - Crear variables dummy
        # ============================================================
        
        # 1. Programa â†’ p_
        if 'Programa' in data.columns:
            print(f"       â†’ Encoding: Programa ({data['Programa'].nunique()} programas)")
            dummies = pd.get_dummies(data['Programa'], prefix='p')
            data = pd.concat([data, dummies], axis=1)
            data.drop(columns=['Programa'], inplace=True)
            print(f"         âœ“ Generadas {len(dummies.columns)} dummies de programas")
        
        # 2. Siglas Prog â†’ s_
        if 'Siglas Prog' in data.columns:
            print(f"       â†’ Encoding: Siglas Prog ({data['Siglas Prog'].nunique()} siglas)")
            dummies = pd.get_dummies(data['Siglas Prog'], prefix='s')
            data = pd.concat([data, dummies], axis=1)
            data.drop(columns=['Siglas Prog'], inplace=True)
            print(f"         âœ“ Generadas {len(dummies.columns)} dummies de siglas")
        
        # 3. Ciudad (DirecciÃ³n) â†’ cd_
        if col_ciudad:
            print(f"       â†’ Encoding: {col_ciudad} ({data[col_ciudad].nunique()} ciudades)")
            dummies = pd.get_dummies(data[col_ciudad], prefix='cd')
            data = pd.concat([data, dummies], axis=1)
            data.drop(columns=[col_ciudad], inplace=True)
            print(f"         âœ“ Generadas {len(dummies.columns)} dummies de ciudades")
        
        # 4. Dpto Nacimiento â†’ dn_
        col_dpto = None
        for c in data.columns:
            if 'Dpto' in c and 'Nacimiento' in c:
                col_dpto = c
                break
        
        if col_dpto:
            print(f"       â†’ Encoding: {col_dpto} ({data[col_dpto].nunique()} departamentos)")
            dummies = pd.get_dummies(data[col_dpto], prefix='dn')
            data = pd.concat([data, dummies], axis=1)
            data.drop(columns=[col_dpto], inplace=True)
            print(f"         âœ“ Generadas {len(dummies.columns)} dummies de departamentos")
        
        # 5. PaÃ­s Nacimiento â†’ pn_
        col_pais = None
        for c in data.columns:
            if 'PaÃ­s' in c and 'Nacimiento' in c:
                col_pais = c
                break
        
        if col_pais:
            print(f"       â†’ Encoding: {col_pais} ({data[col_pais].nunique()} paÃ­ses)")
            dummies = pd.get_dummies(data[col_pais], prefix='pn')
            data = pd.concat([data, dummies], axis=1)
            data.drop(columns=[col_pais], inplace=True)
            print(f"         âœ“ Generadas {len(dummies.columns)} dummies de paÃ­ses")
        
        # 6. AcciÃ³n â†’ a_
        col_accion = None
        for c in data.columns:
            if c == 'AcciÃ³n' or (c.startswith('AcciÃ³n') and '_' in c):
                col_accion = c
                break
        
        if col_accion:
            print(f"       â†’ Encoding: {col_accion} ({data[col_accion].nunique()} acciones)")
            dummies = pd.get_dummies(data[col_accion], prefix='a')
            data = pd.concat([data, dummies], axis=1)
            data.drop(columns=[col_accion], inplace=True)
            cols_accion = [c for c in data.columns if c.startswith('AcciÃ³n')]
            if cols_accion:
                data.drop(columns=cols_accion, inplace=True)
            print(f"         âœ“ Generadas {len(dummies.columns)} dummies de acciones")
        
        # 7. Motivo â†’ m_
        col_motivo = None
        for c in data.columns:
            if c == 'Motivo' or (c.startswith('Motivo') and '_' in c):
                col_motivo = c
                break
        
        if col_motivo:
            print(f"       â†’ Encoding: {col_motivo} ({data[col_motivo].nunique()} motivos)")
            dummies = pd.get_dummies(data[col_motivo], prefix='m')
            data = pd.concat([data, dummies], axis=1)
            data.drop(columns=[col_motivo], inplace=True)
            cols_motivo = [c for c in data.columns if c.startswith('Motivo')]
            if cols_motivo:
                data.drop(columns=cols_motivo, inplace=True)
            print(f"         âœ“ Generadas {len(dummies.columns)} dummies de motivos")
        
        # 8. Cat_ClaseMax â†’ ccmax_
        if 'Cat_ClaseMax' in data.columns:
            print(f"       â†’ Encoding: Cat_ClaseMax ({data['Cat_ClaseMax'].nunique()} categorÃ­as)")
            dummies = pd.get_dummies(data['Cat_ClaseMax'], prefix='ccmax')
            data = pd.concat([data, dummies], axis=1)
            data.drop(columns=['Cat_ClaseMax'], inplace=True)
            print(f"         âœ“ Generadas {len(dummies.columns)} dummies ccmax")
        
        # 9. Cat_ClaseMin â†’ ccmin_
        if 'Cat_ClaseMin' in data.columns:
            print(f"       â†’ Encoding: Cat_ClaseMin ({data['Cat_ClaseMin'].nunique()} categorÃ­as)")
            dummies = pd.get_dummies(data['Cat_ClaseMin'], prefix='ccmin')
            data = pd.concat([data, dummies], axis=1)
            data.drop(columns=['Cat_ClaseMin'], inplace=True)
            print(f"         âœ“ Generadas {len(dummies.columns)} dummies ccmin")
        
        # 10. Tipo AdmisiÃ³n â†’ ta_
        col_tipo_adm = None
        for c in data.columns:
            if 'Tipo' in c and 'AdmisiÃ³n' in c:
                col_tipo_adm = c
                break
        
        if col_tipo_adm:
            print(f"       â†’ Encoding: {col_tipo_adm} ({data[col_tipo_adm].nunique()} tipos)")
            dummies = pd.get_dummies(data[col_tipo_adm], prefix='ta')
            data = pd.concat([data, dummies], axis=1)
            data.drop(columns=[col_tipo_adm], inplace=True)
            print(f"         âœ“ Generadas {len(dummies.columns)} dummies de tipo admisiÃ³n")
        
        # 11. Sexo â†’ numÃ©rico
        col_sexo = None
        for c in data.columns:
            if c == 'Sexo' or (c.startswith('Sexo') and '_' in c):
                col_sexo = c
                break
        
        if col_sexo:
            print(f"       â†’ Encoding: {col_sexo} (numÃ©rico)")
            data['Sexo'] = data[col_sexo].replace({'M': 1, 'F': 0, 'Masculino': 1, 'Femenino': 0})
            if col_sexo != 'Sexo':
                data.drop(columns=[col_sexo], inplace=True)
            cols_sexo = [c for c in data.columns if c.startswith('Sexo') and c != 'Sexo']
            if cols_sexo:
                data.drop(columns=cols_sexo, inplace=True)
        
        # 12. Edad â†’ rangos
        if 'Edad' in data.columns:
            print("       â†’ Encoding: Edad (rangos)")
            def map_age_groups(age):
                if pd.isna(age):
                    return 0
                if age <= 19:
                    return 0
                elif age <= 24:
                    return 1
                else:
                    return 3
            
            data['rango_edad'] = data['Edad'].apply(map_age_groups).astype('int8')
            data.drop(columns=['Edad'], inplace=True)
        
        # Eliminar columnas innecesarias
        cols_eliminar = [
            'ID', 'Nombre', 'Nombre_ppn', 'Nombre_adm', '2Âº Nombre', 'Ãšltima',
            '2Âº Apellido', '2Âº Apellido_per', '2Âº Apellido_prom', 'Apellidos', 'Nombres',
            'Tipo Doc ID', 'Tipo Doc ID_ppn', 'Tipo Doc ID_adm',
            'Doc ID', 'Doc Identidad', 'Tipo Doc Identidad', 'Doc ID_adm', 'Doc ID_ppn',
            'DirecciÃ³n', 'DirecciÃ³n 1', 'DirecciÃ³n 2',
            'TelÃ©fono', 'TelÃ©fono_ppn', 'TelÃ©fono_adm',
            'Correo-E', 'Correo-E_ppn', 'Correo-E_adm', 'Otro Correo E',
            'Celular InscripciÃ³n', 'F Nacimiento', 'F Nacimiento_ppn', 'F Nacimiento_adm',
            'Fecha Grado', 'Estado (DirecciÃ³n)', 'PaÃ­s (DirecciÃ³n)',
            'Ciudad Nacimiento', 'Lugar Nacimiento', 'Colegio', 'Colegio_ppn', 'Colegio_adm',
            'ID Colegio', 'DescripciÃ³n', 'Org Acad', 'Tipo', 'Estado_adm', 'Estado Clase',
            'Prog Acad', 'Prog Acad_ppn', 'Prog Acad_adm', 'Prog Acad.1',
            'Ciclo AdmisiÃ³n_per', 'Ciclo AdmisiÃ³n_prom', 'Ciclo AdmisiÃ³n', 'Situacion Acad',
            'AÃ±o', 'AÃ±o_per', 'AÃ±o_prom', 'Estado', 'Estado_per', 'Estado_ppn', 'Estado_prom',
            'Clase_Min_Ciclo', 'Clase_Max_Ciclo',
            'ID_Min_Ciclo', 'ID_Max_Ciclo', 'Mult Programa', 'Ciclo',
            'ID Curso', 'Calif', 'Uni Matrd', 'Benef. Beca',
            'CrÃ©d Inscritos xa PromedioCicl', 'CrÃ©d.Inscrtos Aprbdos PromCicl'
        ]
        
        cols_encontradas = [c for c in cols_eliminar if c in data.columns]
        if cols_encontradas:
            data.drop(columns=cols_encontradas, inplace=True)
        
        # Eliminar columnas con sufijos
        cols_sufijos = [col for col in data.columns 
                       if any(col.endswith(s) for s in ['_per', '_prom', '_adm', '_ppn', '_pprom', '_notas'])]
        if cols_sufijos:
            print(f"       â†’ Eliminando {len(cols_sufijos)} columnas con sufijos")
            data.drop(columns=cols_sufijos, inplace=True)
        
        # Convertir fechas
        for col in data.select_dtypes(include=['datetime64']).columns:
            try:
                data[col] = (data[col] - pd.Timestamp('1970-01-01')).dt.days
                data[col] = data[col].fillna(0)
            except:
                data.drop(columns=[col], inplace=True)
        
        # Convertir columnas object a numÃ©rico
        for col in data.select_dtypes(include=['object']).columns:
            try:
                data[col] = pd.to_numeric(data[col], errors='coerce')
                data[col] = data[col].fillna(0)
            except:
                print(f"       âš ï¸ No se pudo convertir '{col}', eliminando...")
                data.drop(columns=[col], inplace=True)
        
        print(f"\n       âœ“ Columnas despuÃ©s del encoding: {len(data.columns)}")
        print(f"       âœ“ Tipos de datos finales:")
        print(f"          {data.dtypes.value_counts().to_dict()}")
        
        return data
        """Limpieza final y generaciÃ³n de todas las variables dummy"""
        print("    ðŸ§¹ Iniciando limpieza y encoding...")
        print(f"       Columnas antes: {len(data.columns)}")
        
        # IMPORTANTE: Crear Siglas Prog a partir de Prog Acad si no existe
        if 'Siglas Prog' not in data.columns:
            if 'Prog Acad' in data.columns:
                print("       â†’ Creando 'Siglas Prog' a partir de 'Prog Acad'")
                data['Siglas Prog'] = data['Prog Acad']
            elif 'Prog Acad_ppn' in data.columns:
                print("       â†’ Creando 'Siglas Prog' a partir de 'Prog Acad_ppn'")
                data['Siglas Prog'] = data['Prog Acad_ppn']
            else:
                print("       âš ï¸ NO se puede crear 'Siglas Prog' - NO HAY Prog Acad")
        
        # Normalizar Clase_Min_Ciclo y Clase_Max_Ciclo
        if 'Clase_Min_Ciclo' in data.columns:
            data['Clase_Min_Ciclo'] = data['Clase_Min_Ciclo'].str.title()
            print(f"       âœ“ Clase_Min_Ciclo normalizada: {data['Clase_Min_Ciclo'].nunique()} valores Ãºnicos")
        if 'Clase_Max_Ciclo' in data.columns:
            data['Clase_Max_Ciclo'] = data['Clase_Max_Ciclo'].str.title()
            print(f"       âœ“ Clase_Max_Ciclo normalizada: {data['Clase_Max_Ciclo'].nunique()} valores Ãºnicos")
        
        # Mapear a categorÃ­as
        if self.mapa_categorias and len(self.mapa_categorias) > 0:
            if 'Clase_Min_Ciclo' in data.columns:
                print("       â†’ Mapeando Clase_Min_Ciclo a categorÃ­as...")
                data['Cat_ClaseMin'] = data['Clase_Min_Ciclo'].map(self.mapa_categorias)
                data['Cat_ClaseMin'] = data['Cat_ClaseMin'].fillna('Otros')
                print(f"         CategorÃ­as Min Ãºnicas: {data['Cat_ClaseMin'].nunique()}")
            
            if 'Clase_Max_Ciclo' in data.columns:
                print("       â†’ Mapeando Clase_Max_Ciclo a categorÃ­as...")
                data['Cat_ClaseMax'] = data['Clase_Max_Ciclo'].map(self.mapa_categorias)
                data['Cat_ClaseMax'] = data['Cat_ClaseMax'].fillna('Otros')
                print(f"         CategorÃ­as Max Ãºnicas: {data['Cat_ClaseMax'].nunique()}")
        
        # ENCODING - Crear variables dummy
        
        # 1. Programa â†’ p_
        if 'Programa' in data.columns:
            print(f"       â†’ Encoding: Programa ({data['Programa'].nunique()} programas)")
            dummies = pd.get_dummies(data['Programa'], prefix='p')
            data = pd.concat([data, dummies], axis=1)
            data.drop(columns=['Programa'], inplace=True)
            print(f"         âœ“ Generadas {len(dummies.columns)} dummies de programas")
        
        # 2. Siglas Prog â†’ s_
        if 'Siglas Prog' in data.columns:
            print(f"       â†’ Encoding: Siglas Prog ({data['Siglas Prog'].nunique()} siglas)")
            dummies = pd.get_dummies(data['Siglas Prog'], prefix='s')
            data = pd.concat([data, dummies], axis=1)
            data.drop(columns=['Siglas Prog'], inplace=True)
            print(f"         âœ“ Generadas {len(dummies.columns)} dummies de siglas")
        
        # 3. Ciudad (DirecciÃ³n) â†’ cd_
        col_ciudad = None
        for c in data.columns:
            if 'Ciudad' in c and 'DirecciÃ³n' in c:
                col_ciudad = c
                break
        
        if col_ciudad:
            print(f"       â†’ Encoding: {col_ciudad} ({data[col_ciudad].nunique()} ciudades)")
            dummies = pd.get_dummies(data[col_ciudad], prefix='cd')
            data = pd.concat([data, dummies], axis=1)
            data.drop(columns=[col_ciudad], inplace=True)
            print(f"         âœ“ Generadas {len(dummies.columns)} dummies de ciudades")
        
        # 4. Dpto Nacimiento â†’ dn_
        col_dpto = None
        for c in data.columns:
            if 'Dpto' in c and 'Nacimiento' in c:
                col_dpto = c
                break
        
        if col_dpto:
            print(f"       â†’ Encoding: {col_dpto} ({data[col_dpto].nunique()} departamentos)")
            dummies = pd.get_dummies(data[col_dpto], prefix='dn')
            data = pd.concat([data, dummies], axis=1)
            data.drop(columns=[col_dpto], inplace=True)
            print(f"         âœ“ Generadas {len(dummies.columns)} dummies de departamentos")
        
        # 5. PaÃ­s Nacimiento â†’ pn_
        col_pais = None
        for c in data.columns:
            if 'PaÃ­s' in c and 'Nacimiento' in c:
                col_pais = c
                break
        
        if col_pais:
            print(f"       â†’ Encoding: {col_pais} ({data[col_pais].nunique()} paÃ­ses)")
            dummies = pd.get_dummies(data[col_pais], prefix='pn')
            data = pd.concat([data, dummies], axis=1)
            data.drop(columns=[col_pais], inplace=True)
            print(f"         âœ“ Generadas {len(dummies.columns)} dummies de paÃ­ses")
        
        # 6. AcciÃ³n â†’ a_
        col_accion = None
        for c in data.columns:
            if c == 'AcciÃ³n' or (c.startswith('AcciÃ³n') and '_' in c):
                col_accion = c
                break
        
        if col_accion:
            print(f"       â†’ Encoding: {col_accion} ({data[col_accion].nunique()} acciones)")
            dummies = pd.get_dummies(data[col_accion], prefix='a')
            data = pd.concat([data, dummies], axis=1)
            data.drop(columns=[col_accion], inplace=True)
            # Eliminar otros AcciÃ³n con sufijos
            cols_accion = [c for c in data.columns if c.startswith('AcciÃ³n')]
            if cols_accion:
                data.drop(columns=cols_accion, inplace=True)
            print(f"         âœ“ Generadas {len(dummies.columns)} dummies de acciones")
        
        # 7. Motivo â†’ m_
        col_motivo = None
        for c in data.columns:
            if c == 'Motivo' or (c.startswith('Motivo') and '_' in c):
                col_motivo = c
                break
        
        if col_motivo:
            print(f"       â†’ Encoding: {col_motivo} ({data[col_motivo].nunique()} motivos)")
            dummies = pd.get_dummies(data[col_motivo], prefix='m')
            data = pd.concat([data, dummies], axis=1)
            data.drop(columns=[col_motivo], inplace=True)
            # Eliminar otros Motivo con sufijos
            cols_motivo = [c for c in data.columns if c.startswith('Motivo')]
            if cols_motivo:
                data.drop(columns=cols_motivo, inplace=True)
            print(f"         âœ“ Generadas {len(dummies.columns)} dummies de motivos")
        
        # 8. Cat_ClaseMax â†’ ccmax_
        if 'Cat_ClaseMax' in data.columns:
            print(f"       â†’ Encoding: Cat_ClaseMax ({data['Cat_ClaseMax'].nunique()} categorÃ­as)")
            dummies = pd.get_dummies(data['Cat_ClaseMax'], prefix='ccmax')
            data = pd.concat([data, dummies], axis=1)
            data.drop(columns=['Cat_ClaseMax'], inplace=True)
            print(f"         âœ“ Generadas {len(dummies.columns)} dummies ccmax")
        
        # 9. Cat_ClaseMin â†’ ccmin_
        if 'Cat_ClaseMin' in data.columns:
            print(f"       â†’ Encoding: Cat_ClaseMin ({data['Cat_ClaseMin'].nunique()} categorÃ­as)")
            dummies = pd.get_dummies(data['Cat_ClaseMin'], prefix='ccmin')
            data = pd.concat([data, dummies], axis=1)
            data.drop(columns=['Cat_ClaseMin'], inplace=True)
            print(f"         âœ“ Generadas {len(dummies.columns)} dummies ccmin")
        
        # 10. Tipo AdmisiÃ³n â†’ ta_
        col_tipo_adm = None
        for c in data.columns:
            if 'Tipo' in c and 'AdmisiÃ³n' in c:
                col_tipo_adm = c
                break
        
        if col_tipo_adm:
            print(f"       â†’ Encoding: {col_tipo_adm} ({data[col_tipo_adm].nunique()} tipos)")
            dummies = pd.get_dummies(data[col_tipo_adm], prefix='ta')
            data = pd.concat([data, dummies], axis=1)
            data.drop(columns=[col_tipo_adm], inplace=True)
            print(f"         âœ“ Generadas {len(dummies.columns)} dummies de tipo admisiÃ³n")
        
        # 11. Sexo â†’ numÃ©rico
        col_sexo = None
        for c in data.columns:
            if c == 'Sexo' or (c.startswith('Sexo') and '_' in c):
                col_sexo = c
                break
        
        if col_sexo:
            print(f"       â†’ Encoding: {col_sexo} (numÃ©rico)")
            data['Sexo'] = data[col_sexo].replace({'M': 1, 'F': 0, 'Masculino': 1, 'Femenino': 0})
            if col_sexo != 'Sexo':
                data.drop(columns=[col_sexo], inplace=True)
            # Eliminar otros Sexo con sufijos
            cols_sexo = [c for c in data.columns if c.startswith('Sexo') and c != 'Sexo']
            if cols_sexo:
                data.drop(columns=cols_sexo, inplace=True)
        
        # 12. Edad â†’ rangos
        if 'Edad' in data.columns:
            print("       â†’ Encoding: Edad (rangos)")
            def map_age_groups(age):
                if pd.isna(age):
                    return 0
                if age <= 19:
                    return 0
                elif age <= 24:
                    return 1
                else:
                    return 3
            
            data['rango_edad'] = data['Edad'].apply(map_age_groups).astype('int8')
            data.drop(columns=['Edad'], inplace=True)
        
        # Eliminar columnas innecesarias
        cols_eliminar = [
            'ID', 'Nombre', 'Nombre_ppn', 'Nombre_adm', '2Âº Nombre', 'Ãšltima',
            '2Âº Apellido', '2Âº Apellido_per', '2Âº Apellido_prom', 'Apellidos', 'Nombres',
            'Tipo Doc ID', 'Tipo Doc ID_ppn', 'Tipo Doc ID_adm',
            'Doc ID', 'Doc Identidad', 'Tipo Doc Identidad', 'Doc ID_adm', 'Doc ID_ppn',
            'DirecciÃ³n', 'DirecciÃ³n 1', 'DirecciÃ³n 2',
            'TelÃ©fono', 'TelÃ©fono_ppn', 'TelÃ©fono_adm',
            'Correo-E', 'Correo-E_ppn', 'Correo-E_adm', 'Otro Correo E',
            'Celular InscripciÃ³n', 'F Nacimiento', 'F Nacimiento_ppn', 'F Nacimiento_adm',
            'Fecha Grado', 'Estado (DirecciÃ³n)', 'PaÃ­s (DirecciÃ³n)',
            'Ciudad Nacimiento', 'Lugar Nacimiento', 'Colegio', 'Colegio_ppn', 'Colegio_adm',
            'ID Colegio', 'DescripciÃ³n', 'Org Acad', 'Tipo', 'Estado_adm', 'Estado Clase',
            'Prog Acad', 'Prog Acad_ppn', 'Prog Acad_adm', 'Prog Acad.1',
            'Ciclo AdmisiÃ³n_per', 'Ciclo AdmisiÃ³n_prom', 'Ciclo AdmisiÃ³n', 'Situacion Acad',
            'AÃ±o', 'AÃ±o_per', 'AÃ±o_prom', 'Estado', 'Estado_per', 'Estado_ppn', 'Estado_prom',
            'Clase_Min_Ciclo', 'Clase_Max_Ciclo',
            'ID_Min_Ciclo', 'ID_Max_Ciclo', 'Mult Programa', 'Ciclo',
            'ID Curso', 'Calif', 'Uni Matrd', 'Benef. Beca',
            'CrÃ©d Inscritos xa PromedioCicl', 'CrÃ©d.Inscrtos Aprbdos PromCicl'
        ]
        
        cols_encontradas = [c for c in cols_eliminar if c in data.columns]
        if cols_encontradas:
            data.drop(columns=cols_encontradas, inplace=True)
        
        # Eliminar columnas con sufijos
        cols_sufijos = [col for col in data.columns 
                       if any(col.endswith(s) for s in ['_per', '_prom', '_adm', '_ppn', '_pprom', '_notas'])]
        if cols_sufijos:
            print(f"       â†’ Eliminando {len(cols_sufijos)} columnas con sufijos")
            data.drop(columns=cols_sufijos, inplace=True)
        
        # Convertir fechas
        for col in data.select_dtypes(include=['datetime64']).columns:
            try:
                data[col] = (data[col] - pd.Timestamp('1970-01-01')).dt.days
                data[col] = data[col].fillna(0)
            except:
                data.drop(columns=[col], inplace=True)
        
        # Convertir columnas object a numÃ©rico
        for col in data.select_dtypes(include=['object']).columns:
            try:
                data[col] = pd.to_numeric(data[col], errors='coerce')
                data[col] = data[col].fillna(0)
            except:
                print(f"       âš ï¸ No se pudo convertir '{col}', eliminando...")
                data.drop(columns=[col], inplace=True)
        
        print(f"\n       âœ“ Columnas despuÃ©s del encoding: {len(data.columns)}")
        print(f"       âœ“ Tipos de datos finales:")
        print(f"          {data.dtypes.value_counts().to_dict()}")
        
        return data
        """Limpieza final y generaciÃ³n de todas las variables dummy"""
        print("    ðŸ§¹ Iniciando limpieza y encoding...")
        print(f"       Columnas antes: {len(data.columns)}")
        print(f"       Columnas disponibles: {sorted(data.columns)[:50]}")  # Primeras 50
        
        # Normalizar Clase_Min_Ciclo y Clase_Max_Ciclo
        if 'Clase_Min_Ciclo' in data.columns:
            data['Clase_Min_Ciclo'] = data['Clase_Min_Ciclo'].str.title()
            print(f"       âœ“ Clase_Min_Ciclo normalizada: {data['Clase_Min_Ciclo'].nunique()} valores Ãºnicos")
        if 'Clase_Max_Ciclo' in data.columns:
            data['Clase_Max_Ciclo'] = data['Clase_Max_Ciclo'].str.title()
            print(f"       âœ“ Clase_Max_Ciclo normalizada: {data['Clase_Max_Ciclo'].nunique()} valores Ãºnicos")
        
        # Mapear a categorÃ­as
        if self.mapa_categorias:
            print("       â†’ Mapeando Clase_Min_Ciclo a categorÃ­as...")
            data['Cat_ClaseMin'] = data['Clase_Min_Ciclo'].map(self.mapa_categorias)
            data['Cat_ClaseMin'] = data['Cat_ClaseMin'].fillna('Otros')
            print(f"         CategorÃ­as Min Ãºnicas: {data['Cat_ClaseMin'].nunique()}")
            
            print("       â†’ Mapeando Clase_Max_Ciclo a categorÃ­as...")
            data['Cat_ClaseMax'] = data['Clase_Max_Ciclo'].map(self.mapa_categorias)
            data['Cat_ClaseMax'] = data['Cat_ClaseMax'].fillna('Otros')
            print(f"         CategorÃ­as Max Ãºnicas: {data['Cat_ClaseMax'].nunique()}")
        
        # Buscar columnas clave
        columnas_clave = {
            'Programa': [c for c in data.columns if 'Programa' in c and 'AcadÃ©mico' not in c],
            'Siglas': [c for c in data.columns if 'Siglas' in c],
            'Ciudad': [c for c in data.columns if 'Ciudad' in c and 'DirecciÃ³n' in c],
            'Dpto': [c for c in data.columns if 'Dpto' in c and 'Nacimiento' in c],
            'PaÃ­s': [c for c in data.columns if 'PaÃ­s' in c and 'Nacimiento' in c],
            'AcciÃ³n': [c for c in data.columns if 'AcciÃ³n' in c],
            'Motivo': [c for c in data.columns if 'Motivo' in c],
            'Tipo AdmisiÃ³n': [c for c in data.columns if 'Tipo' in c and 'AdmisiÃ³n' in c],
            'Sexo': [c for c in data.columns if 'Sexo' in c],
            'Edad': [c for c in data.columns if 'Edad' in c],
        }
        
        print("\n       ðŸ“‹ Columnas encontradas para encoding:")
        for nombre, cols in columnas_clave.items():
            if cols:
                print(f"         {nombre}: {cols}")
            else:
                print(f"         {nombre}: âŒ NO ENCONTRADA")
        print()
        
        # ENCODING - Crear variables dummy en el orden del pipeline
        
        # 1. Programa â†’ p_
        if 'Programa' in data.columns:
            print(f"       â†’ Encoding: Programa ({data['Programa'].nunique()} valores)")
            dummies = pd.get_dummies(data['Programa'], prefix='p')
            data = pd.concat([data, dummies], axis=1)
            data.drop(columns=['Programa'], inplace=True)
            print(f"         Generadas {len(dummies.columns)} dummies")
        
        # 2. Siglas Prog â†’ s_
        if 'Siglas Prog' in data.columns:
            print(f"       â†’ Encoding: Siglas Prog ({data['Siglas Prog'].nunique()} valores)")
            dummies = pd.get_dummies(data['Siglas Prog'], prefix='s')
            data = pd.concat([data, dummies], axis=1)
            data.drop(columns=['Siglas Prog'], inplace=True)
            print(f"         Generadas {len(dummies.columns)} dummies")
        
        # 3. Ciudad (DirecciÃ³n) â†’ cd_
        col_ciudad = None
        for c in data.columns:
            if 'Ciudad' in c and 'DirecciÃ³n' in c:
                col_ciudad = c
                break
        
        if col_ciudad:
            print(f"       â†’ Encoding: {col_ciudad} ({data[col_ciudad].nunique()} valores)")
            dummies = pd.get_dummies(data[col_ciudad], prefix='cd')
            data = pd.concat([data, dummies], axis=1)
            data.drop(columns=[col_ciudad], inplace=True)
            print(f"         Generadas {len(dummies.columns)} dummies")
        
        # 4. Dpto Nacimiento â†’ dn_
        col_dpto = None
        for c in data.columns:
            if 'Dpto' in c and 'Nacimiento' in c:
                col_dpto = c
                break
        
        if col_dpto:
            print(f"       â†’ Encoding: {col_dpto} ({data[col_dpto].nunique()} valores)")
            dummies = pd.get_dummies(data[col_dpto], prefix='dn')
            data = pd.concat([data, dummies], axis=1)
            data.drop(columns=[col_dpto], inplace=True)
            print(f"         Generadas {len(dummies.columns)} dummies")
        
        # 5. PaÃ­s Nacimiento â†’ pn_
        col_pais = None
        for c in data.columns:
            if 'PaÃ­s' in c and 'Nacimiento' in c:
                col_pais = c
                break
        
        if col_pais:
            print(f"       â†’ Encoding: {col_pais} ({data[col_pais].nunique()} valores)")
            dummies = pd.get_dummies(data[col_pais], prefix='pn')
            data = pd.concat([data, dummies], axis=1)
            data.drop(columns=[col_pais], inplace=True)
            print(f"         Generadas {len(dummies.columns)} dummies")
        
        # 6. AcciÃ³n â†’ a_
        # Buscar cualquier columna con AcciÃ³n
        col_accion = None
        for c in data.columns:
            if 'AcciÃ³n' in c or 'Accion' in c:
                col_accion = c
                break
        
        if col_accion:
            print(f"       â†’ Encoding: {col_accion} ({data[col_accion].nunique()} valores)")
            dummies = pd.get_dummies(data[col_accion], prefix='a')
            data = pd.concat([data, dummies], axis=1)
            data.drop(columns=[col_accion], inplace=True)
            print(f"         Generadas {len(dummies.columns)} dummies")
        
        # 7. Motivo â†’ m_
        col_motivo = None
        for c in data.columns:
            if 'Motivo' in c:
                col_motivo = c
                break
        
        if col_motivo:
            print(f"       â†’ Encoding: {col_motivo} ({data[col_motivo].nunique()} valores)")
            dummies = pd.get_dummies(data[col_motivo], prefix='m')
            data = pd.concat([data, dummies], axis=1)
            data.drop(columns=[col_motivo], inplace=True)
            print(f"         Generadas {len(dummies.columns)} dummies")
        
        # 8. Cat_ClaseMax â†’ ccmax_
        if 'Cat_ClaseMax' in data.columns:
            print(f"       â†’ Encoding: Cat_ClaseMax ({data['Cat_ClaseMax'].nunique()} valores)")
            dummies = pd.get_dummies(data['Cat_ClaseMax'], prefix='ccmax')
            data = pd.concat([data, dummies], axis=1)
            data.drop(columns=['Cat_ClaseMax'], inplace=True)
            print(f"         Generadas {len(dummies.columns)} dummies")
        
        # 9. Cat_ClaseMin â†’ ccmin_
        if 'Cat_ClaseMin' in data.columns:
            print(f"       â†’ Encoding: Cat_ClaseMin ({data['Cat_ClaseMin'].nunique()} valores)")
            dummies = pd.get_dummies(data['Cat_ClaseMin'], prefix='ccmin')
            data = pd.concat([data, dummies], axis=1)
            data.drop(columns=['Cat_ClaseMin'], inplace=True)
            print(f"         Generadas {len(dummies.columns)} dummies")
        
        # 10. Tipo AdmisiÃ³n â†’ ta_
        col_tipo_adm = None
        for c in data.columns:
            if 'Tipo' in c and 'AdmisiÃ³n' in c:
                col_tipo_adm = c
                break
        
        if col_tipo_adm:
            print(f"       â†’ Encoding: {col_tipo_adm} ({data[col_tipo_adm].nunique()} valores)")
            dummies = pd.get_dummies(data[col_tipo_adm], prefix='ta')
            data = pd.concat([data, dummies], axis=1)
            data.drop(columns=[col_tipo_adm], inplace=True)
            print(f"         Generadas {len(dummies.columns)} dummies")
        
        # 11. Sexo â†’ numÃ©rico
        col_sexo = None
        for c in data.columns:
            if 'Sexo' in c:
                col_sexo = c
                break
        
        if col_sexo:
            print(f"       â†’ Encoding: {col_sexo}")
            data['Sexo'] = data[col_sexo].replace({'M': 1, 'F': 0, 'Masculino': 1, 'Femenino': 0})
            if col_sexo != 'Sexo':
                data.drop(columns=[col_sexo], inplace=True)
        
        # 12. Edad â†’ rangos
        if 'Edad' in data.columns:
            print("       â†’ Encoding: Edad (rangos)")
            def map_age_groups(age):
                if pd.isna(age):
                    return 0
                if age <= 19:
                    return 0
                elif age <= 24:
                    return 1
                else:
                    return 3
            
            data['rango_edad'] = data['Edad'].apply(map_age_groups).astype('int8')
            data.drop(columns=['Edad'], inplace=True)
        
        # Eliminar columnas innecesarias
        cols_eliminar = [
            # IdentificaciÃ³n
            'ID', 'Nombre', 'Nombre_ppn', 'Nombre_adm', '2Âº Nombre', 'Ãšltima',
            '2Âº Apellido', '2Âº Apellido_per', '2Âº Apellido_prom', 'Apellidos', 'Nombres',
            'Tipo Doc ID', 'Tipo Doc ID_ppn', 'Tipo Doc ID_adm',
            'Doc ID', 'Doc Identidad', 'Tipo Doc Identidad',
            'DirecciÃ³n', 'DirecciÃ³n 1', 'DirecciÃ³n 2',
            'TelÃ©fono', 'TelÃ©fono_ppn', 'TelÃ©fono_adm',
            'Correo-E', 'Correo-E_ppn', 'Correo-E_adm', 'Otro Correo E',
            'Celular InscripciÃ³n', 'F Nacimiento', 'F Nacimiento_ppn', 'F Nacimiento_adm',
            'Fecha Grado', 'Estado (DirecciÃ³n)', 'PaÃ­s (DirecciÃ³n)',
            'Ciudad Nacimiento', 'Lugar Nacimiento', 'Colegio', 'Colegio_ppn', 'Colegio_adm',
            'ID Colegio', 'DescripciÃ³n', 'Org Acad', 'Tipo', 'Estado_adm', 'Estado Clase',
            'Prog Acad', 'Prog Acad_ppn', 'Prog Acad_adm', 'Prog Acad.1',
            'Ciclo AdmisiÃ³n_per', 'Ciclo AdmisiÃ³n_prom', 'Situacion Acad',
            'AÃ±o', 'AÃ±o_per', 'AÃ±o_prom', 'Estado', 'Clase_Min_Ciclo', 'Clase_Max_Ciclo',
            'ID_Min_Ciclo', 'ID_Max_Ciclo', 'Mult Programa', 'Ciclo',
            'ID Curso', 'Calif', 'Uni Matrd', 'Benef. Beca'
        ]
        
        cols_encontradas = [c for c in cols_eliminar if c in data.columns]
        if cols_encontradas:
            data.drop(columns=cols_encontradas, inplace=True)
        
        # Eliminar columnas con sufijos
        cols_sufijos = [col for col in data.columns 
                       if any(col.endswith(s) for s in ['_per', '_prom', '_adm', '_ppn', '_pprom', '_notas'])]
        if cols_sufijos:
            data.drop(columns=cols_sufijos, inplace=True)
        
        # Convertir fechas y columnas object a numÃ©rico
        for col in data.select_dtypes(include=['datetime64']).columns:
            try:
                data[col] = (data[col] - pd.Timestamp('1970-01-01')).dt.days
                data[col] = data[col].fillna(0)
            except:
                data.drop(columns=[col], inplace=True)
        
        for col in data.select_dtypes(include=['object']).columns:
            try:
                data[col] = pd.to_numeric(data[col], errors='coerce')
                data[col] = data[col].fillna(0)
            except:
                data.drop(columns=[col], inplace=True)
        
        print(f"\n       âœ“ Columnas despuÃ©s del encoding: {len(data.columns)}")
        print(f"       âœ“ Tipos de datos finales:")
        print(f"          {data.dtypes.value_counts().to_dict()}")
        
        return data
        """Limpieza final y generaciÃ³n de todas las variables dummy"""
        print("    ðŸ§¹ Iniciando limpieza y encoding...")
        print(f"       Columnas antes: {len(data.columns)}")
        
        # Normalizar Clase_Min_Ciclo y Clase_Max_Ciclo
        if 'Clase_Min_Ciclo' in data.columns:
            data['Clase_Min_Ciclo'] = data['Clase_Min_Ciclo'].str.title()
        if 'Clase_Max_Ciclo' in data.columns:
            data['Clase_Max_Ciclo'] = data['Clase_Max_Ciclo'].str.title()
        
        # Mapear a categorÃ­as
        if self.mapa_categorias:
            print("       â†’ Mapeando Clase_Min_Ciclo a categorÃ­as...")
            data['Cat_ClaseMin'] = data['Clase_Min_Ciclo'].map(self.mapa_categorias)
            data['Cat_ClaseMin'].fillna('Otros', inplace=True)
            
            print("       â†’ Mapeando Clase_Max_Ciclo a categorÃ­as...")
            data['Cat_ClaseMax'] = data['Clase_Max_Ciclo'].map(self.mapa_categorias)
            data['Cat_ClaseMax'].fillna('Otros', inplace=True)
        
        # ENCODING - Crear variables dummy en el orden del pipeline
        
        # 1. Programa â†’ p_
        if 'Programa' in data.columns:
            print("       â†’ Encoding: Programa")
            dummies = pd.get_dummies(data['Programa'], prefix='p')
            data = pd.concat([data, dummies], axis=1)
            data.drop(columns=['Programa'], inplace=True)
        
        # 2. Siglas Prog â†’ s_
        if 'Siglas Prog' in data.columns:
            print("       â†’ Encoding: Siglas Prog")
            dummies = pd.get_dummies(data['Siglas Prog'], prefix='s')
            data = pd.concat([data, dummies], axis=1)
            data.drop(columns=['Siglas Prog'], inplace=True)
        
        # 3. Ciudad (DirecciÃ³n) â†’ cd_
        if 'Ciudad (DirecciÃ³n)' in data.columns:
            print("       â†’ Encoding: Ciudad (DirecciÃ³n)")
            dummies = pd.get_dummies(data['Ciudad (DirecciÃ³n)'], prefix='cd')
            data = pd.concat([data, dummies], axis=1)
            data.drop(columns=['Ciudad (DirecciÃ³n)'], inplace=True)
        
        # 4. Dpto Nacimiento â†’ dn_
        if 'Dpto Nacimiento' in data.columns:
            print("       â†’ Encoding: Dpto Nacimiento")
            dummies = pd.get_dummies(data['Dpto Nacimiento'], prefix='dn')
            data = pd.concat([data, dummies], axis=1)
            data.drop(columns=['Dpto Nacimiento'], inplace=True)
        
        # 5. PaÃ­s Nacimiento â†’ pn_
        if 'PaÃ­s Nacimiento' in data.columns:
            print("       â†’ Encoding: PaÃ­s Nacimiento")
            dummies = pd.get_dummies(data['PaÃ­s Nacimiento'], prefix='pn')
            data = pd.concat([data, dummies], axis=1)
            data.drop(columns=['PaÃ­s Nacimiento'], inplace=True)
        
        # 6. AcciÃ³n â†’ a_
        # Resolver duplicados primero
        if 'AcciÃ³n_per' in data.columns:
            data.rename(columns={'AcciÃ³n_per': 'AcciÃ³n'}, inplace=True)
            data.drop(columns=['AcciÃ³n_prom', 'AcciÃ³n_ppn'], inplace=True, errors='ignore')
        
        if 'AcciÃ³n' in data.columns:
            print("       â†’ Encoding: AcciÃ³n")
            dummies = pd.get_dummies(data['AcciÃ³n'], prefix='a')
            data = pd.concat([data, dummies], axis=1)
            data.drop(columns=['AcciÃ³n'], inplace=True)
        
        # 7. Motivo â†’ m_
        if 'Motivo_per' in data.columns:
            data.rename(columns={'Motivo_per': 'Motivo'}, inplace=True)
            data.drop(columns=['Motivo_prom', 'Motivo_ppn'], inplace=True, errors='ignore')
        
        if 'Motivo' in data.columns:
            print("       â†’ Encoding: Motivo")
            dummies = pd.get_dummies(data['Motivo'], prefix='m')
            data = pd.concat([data, dummies], axis=1)
            data.drop(columns=['Motivo'], inplace=True)
        
        # 8. Cat_ClaseMax â†’ ccmax_
        if 'Cat_ClaseMax' in data.columns:
            print("       â†’ Encoding: Cat_ClaseMax")
            dummies = pd.get_dummies(data['Cat_ClaseMax'], prefix='ccmax')
            data = pd.concat([data, dummies], axis=1)
            data.drop(columns=['Cat_ClaseMax'], inplace=True)
        
        # 9. Cat_ClaseMin â†’ ccmin_
        if 'Cat_ClaseMin' in data.columns:
            print("       â†’ Encoding: Cat_ClaseMin")
            dummies = pd.get_dummies(data['Cat_ClaseMin'], prefix='ccmin')
            data = pd.concat([data, dummies], axis=1)
            data.drop(columns=['Cat_ClaseMin'], inplace=True)
        
        # 10. Tipo AdmisiÃ³n â†’ ta_
        if 'Tipo AdmisiÃ³n' in data.columns:
            print("       â†’ Encoding: Tipo AdmisiÃ³n")
            dummies = pd.get_dummies(data['Tipo AdmisiÃ³n'], prefix='ta')
            data = pd.concat([data, dummies], axis=1)
            data.drop(columns=['Tipo AdmisiÃ³n'], inplace=True)
        
        # 11. Sexo â†’ numÃ©rico
        # Resolver duplicados
        if 'Sexo_ppn' in data.columns:
            data.rename(columns={'Sexo_ppn': 'Sexo'}, inplace=True)
            data.drop(columns=['Sexo_adm'], inplace=True, errors='ignore')
        
        if 'Sexo' in data.columns:
            print("       â†’ Encoding: Sexo")
            data['Sexo'] = data['Sexo'].replace({'M': 1, 'F': 0, 'Masculino': 1, 'Femenino': 0})
        
        # 12. Edad â†’ rangos
        if 'Edad' in data.columns:
            print("       â†’ Encoding: Edad (rangos)")
            def map_age_groups(age):
                if pd.isna(age):
                    return 0
                if age <= 19:
                    return 0
                elif age <= 24:
                    return 1
                else:
                    return 3
            
            data['rango_edad'] = data['Edad'].apply(map_age_groups).astype('int8')
            data.drop(columns=['Edad'], inplace=True)
        
        # Eliminar columnas innecesarias
        cols_eliminar = [
            # IdentificaciÃ³n
            'ID', 'Nombre', 'Nombre_ppn', 'Nombre_adm', '2Âº Nombre', 'Ãšltima',
            '2Âº Apellido', '2Âº Apellido_per', '2Âº Apellido_prom', 'Apellidos', 'Nombres',
            'Tipo Doc ID', 'Tipo Doc ID_ppn', 'Tipo Doc ID_adm',
            'Doc ID', 'Doc Identidad', 'Tipo Doc Identidad',
            'DirecciÃ³n', 'DirecciÃ³n 1', 'DirecciÃ³n 2',
            'TelÃ©fono', 'TelÃ©fono_ppn', 'TelÃ©fono_adm',
            'Correo-E', 'Correo-E_ppn', 'Correo-E_adm', 'Otro Correo E',
            'Celular InscripciÃ³n', 'F Nacimiento', 'F Nacimiento_ppn', 'F Nacimiento_adm',
            'Fecha Grado', 'Estado (DirecciÃ³n)', 'PaÃ­s (DirecciÃ³n)',
            'Ciudad Nacimiento', 'Lugar Nacimiento', 'Colegio', 'Colegio_ppn', 'Colegio_adm',
            'ID Colegio', 'DescripciÃ³n', 'Org Acad', 'Tipo', 'Estado_adm', 'Estado Clase',
            'Prog Acad', 'Prog Acad_ppn', 'Prog Acad_adm', 'Prog Acad.1',
            'Ciclo AdmisiÃ³n_per', 'Ciclo AdmisiÃ³n_prom', 'Situacion Acad',
            'AÃ±o', 'AÃ±o_per', 'AÃ±o_prom', 'Estado', 'Clase_Min_Ciclo', 'Clase_Max_Ciclo',
            'ID_Min_Ciclo', 'ID_Max_Ciclo', 'Mult Programa', 'Ciclo',
            'ID Curso', 'Calif', 'Uni Matrd', 'Benef. Beca'
        ]
        
        cols_encontradas = [c for c in cols_eliminar if c in data.columns]
        if cols_encontradas:
            data.drop(columns=cols_encontradas, inplace=True)
        
        # Eliminar columnas con sufijos
        cols_sufijos = [col for col in data.columns 
                       if any(col.endswith(s) for s in ['_per', '_prom', '_adm', '_ppn', '_pprom', '_notas'])]
        if cols_sufijos:
            data.drop(columns=cols_sufijos, inplace=True)
        
        # Convertir fechas y columnas object a numÃ©rico
        for col in data.select_dtypes(include=['datetime64']).columns:
            try:
                data[col] = (data[col] - pd.Timestamp('1970-01-01')).dt.days
                data[col].fillna(0, inplace=True)
            except:
                data.drop(columns=[col], inplace=True)
        
        for col in data.select_dtypes(include=['object']).columns:
            try:
                data[col] = pd.to_numeric(data[col], errors='coerce')
                data[col].fillna(0, inplace=True)
            except:
                data.drop(columns=[col], inplace=True)
        
        print(f"       âœ“ Columnas despuÃ©s: {len(data.columns)}")
        
        return data
    
    def predecir(self, data: pd.DataFrame) -> pd.DataFrame:
        """Realiza predicciones con el modelo XGBoost"""
        print("\nðŸŽ¯ INICIANDO PREDICCIÃ“N...")
        print(f"   Estado del modelo: {'âœ… Cargado' if self.modelo is not None else 'âŒ NO cargado'}")
        print(f"   Tipo de modelo: {type(self.modelo).__name__}")
        print(f"   Registros a predecir: {len(data)}")
        
        if self.modelo is None:
            raise ValueError("âŒ Modelo no cargado")
        
        print("ðŸŽ¯ Realizando predicciones...")
        
        try:
            # Preparar datos
            if self.columnas_modelo is not None:
                for col in self.columnas_modelo:
                    if col not in data.columns:
                        data[col] = 0
                X = data[self.columnas_modelo].copy()
            else:
                X = data.copy()
            
            print(f"   ðŸ“Š Shape de X: {X.shape}")
            
            # Verificar duplicados
            if X.columns.duplicated().any():
                print("   âš ï¸ Columnas duplicadas detectadas, eliminando...")
                X = X.loc[:, ~X.columns.duplicated()]
            
            # Asegurar que todo sea numÃ©rico
            for col in X.columns:
                if X[col].dtype == 'object':
                    X[col] = pd.to_numeric(X[col], errors='coerce').fillna(0)
            
            # Estandarizar
            if self.scaler is not None:
                print("   ðŸ”§ Aplicando scaler...")
                X_scaled = self.scaler.transform(X)
            else:
                X_scaled = X.values
            
            print(f"   ðŸ“Š Shape final: {X_scaled.shape}")
            
            # Predecir
            modelo_tipo = type(self.modelo).__name__
            
            if 'ExponentiatedGradient' in modelo_tipo:
                print("   â„¹ï¸ Detectado modelo con mitigaciÃ³n (ExponentiatedGradient)")
                predicciones = self.modelo.predict(X_scaled)
                probabilidades = np.where(predicciones == 1, 0.9, 0.1)
            else:
                probabilidades = self.modelo.predict_proba(X_scaled)[:, 1]
            
            # Agregar resultados
            resultado = data.copy()
            resultado['probabilidad'] = probabilidades
            resultado['nivel_riesgo'] = pd.cut(
                probabilidades,
                bins=[0, 0.3, 0.6, 1.0],
                labels=["Bajo", "Medio", "Alto"]
            )
            
            print(f"âœ… Predicciones completadas: {len(resultado)} estudiantes")
            print(f"   ðŸŸ¢ Bajo: {(resultado['nivel_riesgo']=='Bajo').sum()}")
            print(f"   ðŸŸ¡ Medio: {(resultado['nivel_riesgo']=='Medio').sum()}")
            print(f"   ðŸ”´ Alto: {(resultado['nivel_riesgo']=='Alto').sum()}")
            
            return resultado
            
        except Exception as e:
            print(f"âŒ Error en predicciÃ³n: {str(e)}")
            import traceback
            traceback.print_exc()
            raise
